---
title: "Stress-testing Phea, test B"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{Stress testing}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

*This vignette assumes a SQL server at `localhost` (we use PostgreSQL), with data in OMOP Common Data Model v5.4 format in schema `cdm_california4`. The patient records shown in this example are synthetic data from [Synthea](https://github.com/synthetichealth/synthea)*[<sup>TM</sup> Patient Generator](https://github.com/synthetichealth/synthea).

```{r, results = 'hide', include = FALSE}
library(knitr)
options(scipen = 5e5)
knitr::opts_chunk$set(collapse = TRUE, comment = "#>")
library(wrap)

cdm_schema <- 'cdm_california4'

usn <- function(n, decimals = 0) {
  sapply(n, function(e) {
    if(is.na(e))
      return(e)
    # usn()'s decimals behave like round()'s digits, but comma()'s precision is different.
    scales::comma(e, 10^(-decimals))
  })
}
```

```{r setup, message = FALSE}
if(!exists('dbcon')) {
  library(dplyr)
  # library(phea)
  devtools::load_all()
  dbcon <- credx::dbConnectFort() # credx is local library.
  setup_phea(dbcon, cdm_schema)
}
```

How complex can a phenotype be in [Phea](https://github.com/fabkury/phea)? And how does performance change as you increase the complexity? Do the queries ever become **too complex**?

Especifically, we talk about two dimensions of complexity:

> A. How many components you can put into one formula.\
> B. How many *consecutive* times can you repeat this: compute a formula, use its results as a component inside another formula.

In this vignette we stress-test Phea in dimension *B*. We are calling this *stress test B*:

> B.  Compute a formula, use the result in a new formula, repeat 1 to 150 times.

The phenotype we compute here is not meaningful in a real-world sense. We just want to test Phea. At the end the results help us see what is going on at technical level.

_For brevity, many parts of the source code are hidden from this report. If you are interested, please download file `stress_test_b.Rmd` from (github.com/fabkury/phea/docs)[<http://github.com/fabkury/phea/docs>]._  

## TL;DR

## The dataset

We use schema ``r cdm_schema``. It has data generated by [Synthea<sup>TM</sup> Patient Generator](https://github.com/synthetichealth/synthea), ETL'ed to OMOP Common Data Model version 5.4 by [ETL-Synthea](https://github.com/OHDSI/ETL-Synthea).

For context, let us glance at the size of that CDM instance.

_Source code is hidden for brevity. Please see stress_test_b.Rmd if interested in the code._

```{r size_stats, include = FALSE}
persons <- sqlt(person) |>
  summarise(persons = n_distinct(person_id)) |>
  pull('persons')

measurement_summary <- paste0('measurement_summary_', cdm_schema) |>
  wrap(by_name = TRUE, pass_val = TRUE, {
    sqlt(measurement) |>
      group_by(measurement_concept_id) |>
      summarise(
        persons = n_distinct(person_id),
        rows = n()) |>
      inner_join(by = c('measurement_concept_id' = 'concept_id'),
        sqlt(concept) |>
          select(concept_id, concept_name)) |>
      arrange(desc(rows), desc(persons)) |>
      collect()
  })

measurement_stats <- paste0('measurement_stats_', cdm_schema) |>
  wrap(by_name = TRUE, pass_val = TRUE, {
    sqlt(measurement) |>
      summarise(
        persons = n_distinct(person_id),
        rows = n()) |>
      collect()
  })
```

Table `PERSON` has **`r usn(as.numeric(persons))` person IDs.**

Table `MEASUREMENT` has **`r usn(as.numeric(measurement_stats$rows))` rows** across **`r usn(as.numeric(measurement_stats$persons))` patients**.

Below we show the top 6 rows of the *summary table*, that is, the top 6 most popular concepts in `MEASUREMENT` by number of rows.

```{r measurement_summary_peek}
kable(measurement_summary[1:6,])
```

That is the data we will use to benchmark Phea.

Each component will be exactly this:

``` sql
SELECT *
FROM cdm_california4.measurement
WHERE measurement_concept_id = [chosen concept]
```

In other words, each component uses a different `measurement_concept_id` from the *summary table* to `SELECT *` from table `MEASUREMENT`.

We will be picking rows (concepts) from the *summary table* in descending order starting from the first. To reduce bias, let us shuffle that table, so it is no longer sorted by descending order of rows.  

```{r}
set.seed(42)
measurement_summary <- measurement_summary[sample(1:nrow(measurement_summary)),]
```

## Computer used to run this test

This was the machine used to execute this test:

> Processor Intel(R) Core(TM) i7-10750H CPU \@ 2.60GHz 2.59 GHz\
> Installed RAM 64.0 GB (63.8 GB usable)\
> System type 64-bit operating system, x64-based processor

## Formulas used for testing

In each iteration of test B, we want to take the result of the prior formula (prior iteration) and add a random number to it. On top of that, to improve realism, we will add the `value_as_number` of 4 _new_ components. Therefore our formula in each iteration is:  

> **test_b**<sub>n</sub> = test_b<sub>n-1</sub> + random() + W + X + Y + Z

That formula will be computed for all patients at all points in time.  

<!-- By definition, the points in time are the union of all timestamps from every component ever included in the formula. This also means that the timestamps from a prior iteration carry over to the next. Therefore once a timestamp is in, it never leaves the results. Once all concepts from _summary table_ have been used, the timestamps will be effectively all timestamps present in table `MEASUREMENT`.   -->

Each iteration will use different W, X, Y and Z. They will be picked in descending order from the _summary table_, which has been shuffled.  

If we reach the end of _summary table_ and still need more components, we just cycle back to the first row.  

The first iteration, test_b<sub>1</sub>,  uses zero as result from prior run:  

> **test_b**<sub>0</sub> = 0

All persons extant in table `MEASUREMENT` will participate. Each person will be running its own random walk.  

We use library `tictoc` to measure the time spent in each iteration.  

```{r}
library(tictoc)
```

## Functions used for the test

Function `produce_N_components(N)` produces `N` components using the first `N` rows of `measurement_summary`.

```{r, include = FALSE}
produce_N_components <- function(N, offset = 0) {
  make_test_component <- function(i) {
    concept_id <- measurement_summary$measurement_concept_id[i]
    component <- sqlt(measurement) |>
      filter(measurement_concept_id == local(concept_id)) |>
      make_component(
        .ts = measurement_datetime,
        .pid = person_id)
    return(component)
  }
  
  selected <- (1+offset):(N+offset)
  selected <- (selected-1) %% nrow(measurement_summary) + 1 # Cycle if past end
  
  # Pick the selected lab tests
  components <- lapply(selected, make_test_component)
  
  # Their names will be simply "C<sub>n</sub>"
  names(components) <- paste0('c', selected)
  
  return(components)
}
```

Function `run_test_b(N)` runs Test B `N` consecute times.

```{r, include = FALSE}
iterate_test_b <- function(prior_result, i, n_components) {
  new_components <- produce_N_components(n_components, i)
  
  new_components_string <- paste0('coalesce(', names(new_components), '_value_as_number, 0)', collapse = ' + ')
  test_b_formula <- paste0('prior_test_b + r_value + ', new_components_string)
  
  prior_test_b <- make_component(prior_result, .pid = pid, .ts = ts)
  
  new_result <- calculate_formula(
    components = c(list(prior = prior_test_b), new_components),
    fml = list(
      r_value = 'random()',
      test_b = test_b_formula),
    kco = TRUE)
  
  new_result
}


run_test_b <- function(N) {
  n_extra_components <- 4
  paste0('phea_test_b_c', n_extra_components, '_', N, '_', cdm_schema) |>
    wrap(by_name = TRUE, assign_val = FALSE, pass_val = TRUE, {
      message('Running run_test_b(', N, ')')
      # Gather all persons from table PERSON.
      phenotype <- sqlt(person) |>
        transmute(
          # Names must match output from calculate_formula().
          pid = person_id,
          ts = birth_datetime,
          test_b = 0)
      
      tic()
      for(i in 1:N)
        phenotype <- iterate_test_b(phenotype, (i-1)*n_extra_components + 1, n_extra_components)
      phea_time <- toc(quiet = TRUE)
      phea_time <- phea_time$toc - phea_time$tic
      tic()
      aggregate <- phenotype |>
        group_by() |>
        summarise(
          rows = n(),
          patients = n_distinct(pid),
          test_b_sum_K = sum(test_b/1000, na.rm = TRUE)) |>
        collect() |>
        mutate(`N` = local(N), `CX` = local(n_extra_components))
      query_time <- toc(quiet = TRUE)
      query_time <- query_time$toc - query_time$tic
      
      # phenotype_head
        
      res <- list(
        N = N,
        # result = phenotype,
        aggregate = aggregate,
        phea_time = phea_time,
        query_time = query_time)
      
      res
    })
}

```

_For economy of space, these functions are not printed here. You can obtain them by downloading the `stress_test_b.Rmd` file at (github.com/fabkury/phea/docs)[<http://github.com/fabkury/phea/docs>]._

## Run N = 1

```{r}
test_b_runs = list()
```
```{r, echo = FALSE}
make_results_table <- function(data) {
  purrr::map_df(data, \(x) {
    list(
      N = x$N,
      `Rows` = usn(as.numeric(x$aggregate$rows)),
      `Patients` = usn(as.numeric(x$aggregate$patients)),
      `B sum (K)` = usn(x$aggregate$test_b_sum_K, 1),
      `Phea time (min)` = usn(x$phea_time/60, 2),
      `Query time (min)` = usn(x$query_time/60, 2))
    })
}
```
Let's first run Test A with N = 1, that is, a single component.

```{r test_a_1, results = 'hide', message = FALSE}
test_b_runs[[length(test_b_runs)+1]] <- run_test_b(1)
```

Done!  

How was the performance? Let's see.
```{r, include = FALSE}
print_test_b_results <- function() {
  kable(make_results_table(test_b_runs))
}
```
```{r}
print_test_b_results()
```

<!-- Here are the meanings of the columns:   -->

<!--  - **N**: Number of components included in the run.   -->

<!--  - **in. rows**: Total number of rows in the record sources provided to `calculate_formula()`.   -->

<!--  - **res. rows**: Total number of rows in the phenotype returned by `calculate_formula()`.   -->

<!--  - **test_a_sum**: Sum of the result of the formula across all patients.   -->

<!--  - **in. patients**: Number of patients in the record sources.     -->

<!--  - **res. patients**: Number of patients in the resulting phenotype.    -->

<!--  - **Phea time**: Time spent by `calculate_formula()`, in seconds.   -->

<!--  - **query time**: Time spent to run (`collect()`) the phenotype (aggregated), in seconds.    -->

<!--  - **query pps**: Input patients processed per second of query time.   -->

<!--  - **query rps**: Input rows processed per second of query time.   -->

## Run N = 5

```{r test_b_5, message = FALSE}
test_b_runs[[length(test_b_runs)+1]] <- run_test_b(5)

print_test_b_results()
```

With N = `r test_b_runs[[2]]$N` (number of components), Phea took `r test_b_runs[[2]]$phea_time` sec to assemble the phenotype, and the SQL server took `r test_b_runs[[2]]$query_time` sec to run the query.

## Runs N = 10 to N = 150

Now that we have a grip on how Test B works, let's run it for N = 10 to 150, increasing 10 at a time.

```{r test_a_10_150}
N <- 10
N_max <- 150
try({
  while(N <= N_max) {
    test_b_runs[[length(test_b_runs)+1]] <- run_test_b(N)
    N <- N + 5
  }
})
```

## Test B results
```{r, echo = FALSE}
print_test_b_results()
```

### Author contact

Fabrício Kury\
`r format(Sys.time(), '%Y/%b/%d')`\
Be always welcome to reach me at [fab\@kury.dev](mailto:fab@kury.dev){.email}.

```{r, include = FALSE}
DBI::dbDisconnect(dbcon)
```
